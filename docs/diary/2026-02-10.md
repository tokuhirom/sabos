# 2026-02-10 開発日記

## 今日の目標

TODO.md の「IPC 基盤の改善」3 項目を一気に片付けたい。具体的には:

1. IPC recv のポーリングを Sleep/Wake 方式に改修して CPU 浪費を止める
2. recv のキャンセル機構を追加する
3. IPC 経由で Capability（ハンドル）を委譲できるようにする

マイクロカーネルへの道のりとして、IPC はまさに心臓部。ここを良くしておけば、将来ファイルシステムやネットワークをユーザー空間に移したときに、ちゃんと動くはず。

## IPC recv の Sleep/Wake 化

### 問題

これまでの `recv()` は `loop { try_recv(); yield_now(); }` というポーリング方式だった。タスクは常に Ready 状態のままで、PIT の ~55ms 間隔でしか受信チェックされない。つまり:

- CPU サイクルを無駄に消費する（Ready なので毎回スケジューリングされる）
- レイテンシが悪い（最悪 55ms 待たされる）

### 解決策

futex.rs で使っている `set_current_sleeping` + `wake_task` パターンをそのまま IPC にも適用した。

```
send() 側:
  1. メッセージをキューに追加
  2. dest が IPC_WAITERS にいれば wake_task(dest) で起床

recv() 側:
  1. try_recv() で即チェック → あればすぐ返す
  2. IPC_WAITERS に自分を登録
  3. set_current_sleeping(wake_at) で Sleeping に遷移
  4. ダブルチェック: もう一度 try_recv → 来ていたら自分を起こして返す
  5. yield_now() でスケジューラに制御を渡す
  6. 起床後: WAITERS 除去、キャンセルチェック、try_recv
```

ステップ 4 の「ダブルチェック」が重要。`set_current_sleeping` と `yield_now` の間に `send()` が来た場合、wake_task は Sleeping→Ready にするだけなので、まだ yield していなければ効果がない。だからもう一度 try_recv して、メッセージが来ていたら自分で自分を起こす。

これは futex_wait() でも「値チェック → TABLE 登録 → sleeping → yield」の順序で同じ考慮をしている。並行プログラミングの定番パターン（ダブルチェックロッキングの変形）。

### IPC_WAITERS と IPC_CANCELLED

新たに 2 つのグローバルデータ構造を追加:

- `IPC_WAITERS: Mutex<BTreeSet<u64>>` — recv 待ちタスクの集合
- `IPC_CANCELLED: Mutex<BTreeSet<u64>>` — キャンセルされたタスクの集合

BTreeSet を使ったのは、contains / insert / remove が O(log n) で、タスク数が少ない SABOS では十分速いから。

## キャンセル機構: SYS_IPC_CANCEL (92)

`cancel_recv(target_task_id)` を呼ぶと:

1. `IPC_CANCELLED` にターゲットを追加
2. `wake_task(target_task_id)` で起床させる

起床した recv 側は、try_recv でメッセージがなく、CANCELLED チェックでフラグが立っていたら `Cancelled` エラーを返す。

新しいエラーコード `-50` (Cancelled) を `SyscallError` に追加した。エラーコード体系:
- 1-9: ポインタ・メモリ関連
- 10-19: 引数・データ形式関連
- 20-29: ファイル・ハンドル関連
- 30-39: 権限・セキュリティ関連
- 40-49: システム関連
- **50-59: IPC 関連** ← NEW

## Capability 委譲: SYS_IPC_SEND_HANDLE (93) / SYS_IPC_RECV_HANDLE (94)

マイクロカーネルの核心部分。IPC メッセージにハンドル（Capability）を付けて送受信できるようにした。

### duplicate_handle

handle.rs に `duplicate_handle()` を追加した。元のハンドルと同じ rights/kind/path/data を持つ新しいハンドルを作成する。token は新規生成、pos は 0 にリセット。

なぜ duplicate するかというと、送信元のハンドルと受信先のハンドルは独立した存在であるべきだから。送信後に元ハンドルを close しても、受信側のハンドルは生きている。逆に、受信側がハンドルを close しても送信元には影響しない。

### IPC_HANDLE_QUEUES

通常の `IPC_QUEUES` とは別に、ハンドル付きメッセージ専用のキュー `IPC_HANDLE_QUEUES` を持つ。分けた理由は、通常メッセージとハンドル付きメッセージを混在させると型が複雑になるし、タスク終了時のクリーンアップでハンドルの close が必要なため。

`cleanup_task()` では、未読のハンドル付きメッセージのハンドルも close するようにした。これがないと、受信者が先に死んだ場合にハンドルがリークする。

### recv_with_handle

タイムアウトなしで、`cancel_recv()` でキャンセルされるまで待つ設計にした。これはマイクロカーネルの IPC パターンに合わせている — サーバーはクライアントからの要求を無期限に待ち、必要に応じてキャンセルする。

## IPC ベンチマーク: ipc_bench コマンド

rdtsc 命令（TSC: Time Stamp Counter）を使って、send+recv のラウンドトリップを N 回計測する。min/avg/max のサイクル数を表示する。

TSC（Time Stamp Counter）は x86 CPU のクロックサイクルカウンタで、rdtsc 命令で読み取れる。1 サイクル単位の精度があるので、マイクロベンチマークに最適。ただし、省電力機能で CPU クロックが変動する環境では注意が必要（QEMU ではほぼ一定）。

10 回のウォームアップを入れてから本計測する。

## selftest 追加

### ipc_cancel テスト

selftest は単一タスクで動くので、「別タスクから cancel する」テストはできない。代わりに、自分自身を cancel 対象にしてから recv する方式にした:

1. `cancel_recv(自分)` → CANCELLED フラグが立つ + wake_task（自分は Running なので無効）
2. `recv(自分, 1000)` → try_recv(なし) → sleep → yield → 起床（cancel の wake で） → CANCELLED チェック → Cancelled エラー

### ipc_handle テスト

1. テスト用ファイルハンドル（`"IPC handle test data"`）を作成
2. 自分自身にハンドル付きメッセージを送信
3. `try_recv_with_handle()` で即座に受信（自分宛なのでキューにある）
4. 受信したハンドルで read して、元のデータと一致するか確認
5. 両方のハンドルを close

## テスト結果

```
make test → 全テスト PASS（ipc_cancel, ipc_handle 含む）
```

既存の ipc, ipc_typed テストも引き続き PASS。Sleep/Wake 化しても後方互換性は維持できた。

## 振り返り

### 良かった点

- futex.rs のパターンをそのまま流用できた。一度学んだパターンが再利用できるのは気持ちいい
- ダブルチェックパターンを忘れずに入れられた。並行処理の罠を踏まずに済んだ
- TODO.md の 3 項目を一気に片付けられた

### 学んだこと

- **ダブルチェックパターン**: Sleep に遷移した直後に、もう一度条件をチェックすることで TOCTOU（Time Of Check To Time Of Use）レースを防ぐ。これは futex でも IPC でも共通の重要パターン
- **Capability 委譲の設計**: 送信元と受信先のハンドルは独立すべき。duplicate + 別 token で実現。close の責任が明確になる
- **rdtsc**: x86 の TSC カウンタはマイクロベンチマークに便利。インラインアセンブリで `out("eax")` と `out("edx")` を使って 64 ビット値を組み立てる

### 次にやりたいこと

- ipc_bench の結果を実際に見てみたい（手動で `make run-gui` して `ipc_bench` コマンドを叩く）
- 型安全 IPC (recv_typed) も Sleep/Wake 化したので、netd との通信が速くなっているはず
- HELLOSTD.ELF の IPC タイムアウト問題が改善されたか確認したい（Sleep/Wake 化でレイテンシが改善しているかも）

## IPC recv ループ修正

### 問題

IPC の `recv()` が1回の sleep-wake サイクルで終了していた。具体的には:

1. `try_recv()` → メッセージなし
2. `set_current_sleeping(deadline)` で寝る
3. タイマーで起床（メッセージが来たからではなく、PIT 割り込みで）
4. `try_recv()` → まだメッセージなし → **即 Timeout を返す**

これだと、タイムアウト時間が残っていてもメッセージを受信できない。netd の DNS ルックアップは数秒かかるので、HELLOSTD.ELF のネットワークテストが「タイムアウト設定は長いのにすぐ諦める」という症状になっていた。

### 解決策

`recv()`, `recv_typed()`, `recv_with_handle()` の 3 関数をすべてループ化した。

```
loop {
    try_recv → あれば返す
    is_deadline_reached → タイムアウトなら Timeout
    WAITERS 登録 → sleep → ダブルチェック → yield
    起床後: キャンセルチェック → ループ先頭に戻る
}
```

`is_deadline_reached()` ヘルパーを追加。deadline が `u64::MAX`（無期限待ち）なら常に false、それ以外は現在のタイマーティックと比較する。

### フレーキーテスト対策

テスト中に `[FAIL] ipc` と `[FAIL] ipc_cancel` が不安定に発生する問題を発見した。調査の結果:

- ループ修正前（前のコミット）でも同じ失敗が再現 → ループ修正が原因ではない
- 別の実行では 47/47 全パス → タイミング依存のフレーキーテスト

原因の仮説: ネットワークテスト等から遅延 IPC メッセージがカーネルシェルのキューに残ることがある。`test_ipc` の `try_recv` でそれを先に拾ってしまい、期待する "ping" と一致しない。

対策: `test_ipc` と `test_ipc_cancel` の先頭で `while try_recv().is_some() {}` でキューをドレインするようにした。

### テスト結果

```
make test → 47/47 PASSED（ipc, ipc_cancel, ipc_handle 含む）
```
