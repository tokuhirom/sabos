# 2026-02-19: ネットワーク実機対応 Phase 2 一気に完了！

## 今日の目標

実機対応ロードマップの Phase 2（ネットワーク実機対応）を進めたい。Phase 2-1「ARP キャッシュ」、Phase 2-2「DHCP クライアント」、Phase 2-3「e1000e NIC ドライバ」の 3 つを一気に片付けて、ネットワーク周りの実機対応を完了させたい。

---

## Phase 2-1: ARP キャッシュ — ブロードキャスト MAC からの脱却

実機対応ロードマップの Phase 2-1「ARP キャッシュと正しい MAC 解決」を実装した。これまで SABOS のネットワークスタックは、すべての送信パケットで宛先 MAC アドレスをブロードキャスト（FF:FF:FF:FF:FF:FF）にハードコードしていた。QEMU の SLIRP ネットワークではこれでも動くが、実ネットワークではスイッチが正しく転送してくれないため、ARP（Address Resolution Protocol）による正しい MAC 解決が必要になる。これまで SABOS のネットワークスタックは、すべての送信パケットで宛先 MAC アドレスをブロードキャスト（FF:FF:FF:FF:FF:FF）にハードコードしていた。QEMU の SLIRP ネットワークではこれでも動くが、実ネットワークではスイッチが正しく転送してくれないため、ARP（Address Resolution Protocol）による正しい MAC 解決が必要になる。

## やったこと

### ARP とは

ARP は IP アドレスから MAC アドレスを解決するためのプロトコル。Ethernet 上で通信するには宛先の MAC アドレスが必要だが、アプリケーションが知っているのは IP アドレスだけ。ARP Request をブロードキャストで送信し、該当 IP のホストが ARP Reply でユニキャスト応答することで、IP → MAC のマッピングを得る。このマッピングをキャッシュしておくのが ARP キャッシュ（ARP テーブル）。

### ARP キャッシュの設計

`NetState` に `arp_cache: Vec<ArpEntry>` を追加した。`ArpEntry` は `{ ip: [u8; 4], mac: [u8; 6] }` のシンプルな構造体。最大 64 エントリで、溢れたら先頭（最も古いもの）を削除する LRU 風の管理にした。TTL による有効期限管理は今回は見送り。

```rust
struct ArpEntry {
    ip: [u8; 4],
    mac: [u8; 6],
}
```

操作関数は 2 つ:
- `arp_lookup(ip)` — キャッシュから MAC を検索
- `arp_update(ip, mac)` — キャッシュに追加/更新

### ARP 学習の拡張

既存の `handle_arp()` は ARP Request を受信して Reply を返すだけだった。これを拡張して:

1. **すべての ARP パケット**（Request/Reply 両方）から送信元 IP/MAC をキャッシュに学習するようにした。Gratuitous ARP（自分の IP を問い合わせる特殊な ARP）にも対応。
2. **IPv4 パケット受信時**にも、Ethernet ヘッダの送信元 MAC と IPv4 ヘッダの送信元 IP をキャッシュに学習するようにした。これにより、ICMP Echo Reply 等の応答を返す際に ARP Request なしで即座に MAC を解決できる。

### ARP Request 送信

`send_arp_request(target_ip)` を新規実装した。宛先 MAC をブロードキャスト、ターゲット MAC をゼロ（不明）にして ARP Request を送信する。

### resolve_mac — MAC アドレス解決の全フロー

`resolve_mac(dst_ip)` が今回の実装の中核。以下のフローで MAC を解決する:

1. ブロードキャスト IP (255.255.255.255) → そのままブロードキャスト MAC を返す
2. サブネット判定（10.0.2.0/24）。サブネット外ならゲートウェイ IP (10.0.2.2) の MAC を解決対象にする
3. ARP キャッシュを検索 → ヒットすれば返す
4. ミスなら ARP Request を送信し、`wait_net_condition` で応答を待つ
5. 最大 3 回リトライ、各回 1000ms タイムアウト

### net_poller デッドロック問題

ここで一つ面白い問題に遭遇した。`resolve_mac()` は `wait_net_condition()` を使って ARP Reply を待つが、この関数は net_poller タスクがパケットを処理して waiter を起床させることを前提としている。ところが `send_icmp_echo_reply()` や `send_tcp_packet_internal()` は net_poller タスク自身から呼ばれる（handle_packet → handle_ipv4 → handle_icmp → send_icmp_echo_reply の流れ）。もし net_poller 内で `resolve_mac()` を呼んで `wait_net_condition()` でスリープしたら、パケットを処理するタスクがいなくなってデッドロックする。

解決策として、関数の呼び出しコンテキストに応じて使い分けた:

| 関数 | コンテキスト | MAC 解決方法 |
|------|-------------|-------------|
| `send_udp_packet` | ユーザータスク | `resolve_mac()` でブロッキング解決 |
| `tcp_connect` | ユーザータスク | SYN 送信前に `resolve_mac()` でキャッシュを温める |
| `send_tcp_packet_internal` | net_poller / ユーザータスク | `arp_lookup()` で非ブロッキング（ミス時は BROADCAST_MAC フォールバック） |
| `send_icmp_echo_reply` | net_poller | `arp_lookup()` で非ブロッキング（handle_ipv4 で学習済み） |

`send_tcp_packet_internal` が net_poller から呼ばれるケースは、受信したパケットへの応答（SYN-ACK, ACK 等）なので、直前の `handle_ipv4` で送信元 MAC を学習済み。つまり `arp_lookup` はほぼ確実にヒットする。

### selftest

`arp_resolve` テストを追加した。`resolve_mac(&GATEWAY_IP)` でゲートウェイ（10.0.2.2）の MAC が解決できることを確認する。QEMU SLIRP は ARP に正しく応答するので、ARP Request → Reply → キャッシュ → MAC 返却の全フローがテストされる。

## テスト結果

```
=== SELFTEST END: 57/57 PASSED ===
```

新規追加の `arp_resolve` を含む全 57 テストが PASS。

## 気づき

- ARP キャッシュの実装自体はシンプルだが、**どのコンテキストから呼ばれるか**を意識する必要があった。カーネル内のネットワークスタックでは、パケット処理タスク（net_poller）と通常タスクが同じ関数を呼ぶケースがあり、ブロッキング/非ブロッキングの使い分けが重要。
- IPv4 パケット受信時にも送信元 MAC を学習するようにしたのは良い判断だった。ARP パケットだけでなく、通常のデータパケットからも MAC を学べるので、ARP キャッシュの温まりが速くなる。
- TTL 管理は今回見送ったが、実環境では ARP エントリの有効期限管理が必要になる。TODO に残してある。

---

## Phase 2-2: DHCP クライアント — IP アドレスの動的取得

### DHCP とは

DHCP (Dynamic Host Configuration Protocol) は、ネットワーク上のデバイスに IP アドレスやサブネットマスク、ゲートウェイ、DNS サーバーなどの設定を自動的に割り当てるプロトコル。これまで SABOS は IP アドレスを 10.0.2.15 にハードコードしていた。QEMU の SLIRP ではたまたまこの IP がデフォルトだったが、実ネットワークでは DHCP で動的に取得する必要がある。

### 実装の準備：ネットワーク設定の動的化

DHCP を実装する前提として、IP アドレスやゲートウェイ等のネットワーク設定を `const` から `static Mutex` に変更する必要があった。`kernel/src/net_config.rs` を新設して、実行時に設定を書き換えられるようにした。初期値は QEMU SLIRP のデフォルト値（10.0.2.15 等）を維持し、DHCP が成功したら上書きする。失敗してもデフォルトが残るので安全。

### DHCP 4 ステップ

DHCP のプロトコルは 4 つのメッセージで構成される:

1. **Discover** — クライアントがブロードキャストで「IP ください」と要求
2. **Offer** — サーバーが「この IP どうですか」と提案
3. **Request** — クライアントが「その IP をお願いします」と確認
4. **Ack** — サーバーが「OK、割り当てました」と承認

実装では `dhcp_discover()` 関数として、Discover → Offer 待ち → Request → Ack 待ちの全フローを 1 つの関数にまとめた。UDP ポート 68（クライアント）で受信し、ポート 67（サーバー）に送信する。

### DHCP オプションのパース

DHCP メッセージには「オプション」フィールドがあり、TLV (Type-Length-Value) 形式で様々な情報が格納される。重要なのは:

- Option 1: サブネットマスク
- Option 3: デフォルトゲートウェイ
- Option 6: DNS サーバー
- Option 51: リース時間
- Option 53: メッセージタイプ（Offer / Ack の判定に使う）
- Option 54: DHCP サーバーの IP

マジックナンバー `0x63825363` で始まるオプション領域をパースして、上記の値を取得する。

### テスト結果

```
=== SELFTEST END: 58/58 PASSED ===
```

新規追加の `dhcp_config` テストを含む全 58 テストが PASS。`dhcp_config` は DHCP で取得した IP がデフォルト値（0.0.0.0）でないことを確認する。

---

## Phase 2-3: e1000e NIC ドライバ — 初の実 NIC ドライバ

### なぜ e1000e か

SABOS のネットワークは virtio-net だけに対応していた。virtio-net は QEMU 向けの仮想デバイスで、実機には存在しない。実機でネットワークを使うには実際の NIC (Network Interface Card) のドライバが必要。Intel e1000e (82574L) を選んだ理由は:

1. **広く普及** — 多くのサーバーやビジネス PC に搭載
2. **仕様公開** — Intel がデータシートを公開している
3. **QEMU でテスト可能** — `-device e1000e` でエミュレート可能
4. **シンプル** — 最新の NIC に比べてプログラミングモデルが素直

### e1000e の仕組み

e1000e は MMIO（Memory-Mapped I/O）でレジスタにアクセスする。PCI の BAR0 にマップされた物理アドレスに対して、read_volatile / write_volatile で読み書きする。NVMe ドライバと同じパターン。

パケットの送受信は **ディスクリプタリング**（リングバッファ）で管理する。RX リングと TX リングの 2 つがあり、それぞれ 32 個のディスクリプタ（16 バイト）を持つ。

- **RX（受信）**: ハードウェアがパケットを受信すると、ディスクリプタの `addr` が指すバッファにデータを書き込み、`status` の DD ビットをセットする。ソフトウェアは DD ビットをポーリングして受信を検出する。
- **TX（送信）**: ソフトウェアがディスクリプタに送信データのアドレスと長さをセットし、TDT（Tail）レジスタを更新する。ハードウェアが送信完了すると DD ビットをセットする。

### 初期化シーケンス

1. PCI Bus Master + Memory Space を有効化
2. BAR0（MMIO ベースアドレス）を取得
3. CTRL レジスタの RST ビットでデバイスリセット
4. IMC レジスタで全割り込みを無効化（ポーリングモード）
5. CTRL の SLU ビットでリンクアップを強制
6. RAL/RAH レジスタから MAC アドレスを読み取り
7. RX/TX ディスクリプタリングとバッファを `alloc_zeroed` で確保
8. RDBAL/RDBAH/RDLEN/RDH/RDT レジスタを設定
9. TDBAL/TDBAH/TDLEN/TDH/TDT レジスタを設定
10. RCTL で受信有効化、TCTL で送信有効化

### BAR の 32-bit / 64-bit 判定

最初にハマったのが BAR0 の読み取り。計画では `read_bar64()` で 64-bit として読み取る想定だったが、QEMU の e1000e は **32-bit MMIO BAR** を使っていた。BAR0 を 64-bit として読むと、BAR1 の値が上位 32 ビットに混入してアドレスがおかしくなり、MMIO アクセスで General Protection Fault が発生した。

解決策として、BAR の type bits ([2:1]) を確認してから 32-bit / 64-bit を判定するようにした:

```rust
let bar0_low = pci::read_bar(dev.bus, dev.device, dev.function, 0);
let bar_type = (bar0_low >> 1) & 0x03;
let bar0 = if bar_type == 0x02 {
    // 64-bit MMIO
    pci::read_bar64(dev.bus, dev.device, dev.function, 0) & !0xF
} else {
    // 32-bit MMIO
    (bar0_low & !0xF) as u64
};
```

NVMe は 64-bit BAR を使うので `read_bar64()` で問題なかったが、e1000e は 32-bit だった。デバイスごとに BAR のサイズが異なることを学んだ。

### netstack の NIC 抽象化

ドライバだけ作っても、netstack が virtio-net を直接参照しているままでは e1000e が使われない。`send_frame()` / `recv_frame_nonblocking()` / `kick_virtio_net()` を抽象化して、virtio-net → e1000e のフォールバック順で動作するように変更した:

```rust
fn send_frame(data: &[u8]) -> Result<(), &'static str> {
    // virtio-net を優先（QEMU デフォルト）
    if let Some(ref mut d) = *crate::virtio_net::VIRTIO_NET.lock() {
        return d.send_packet(data);
    }
    // e1000e にフォールバック
    if let Some(ref mut d) = *crate::e1000e::E1000E.lock() {
        return d.send_packet(data);
    }
    Err("no network device available")
}
```

`kick_virtio_net()` も `kick_net_device()` にリネームし、e1000e の場合は ICR レジスタを read-to-clear する処理に変更した。

`netstack::init()` も同様に、virtio-net → e1000e の順で MAC アドレスを取得するように変更。QEMU では両方のデバイスが存在するが、virtio-net が優先されるので既存の動作に影響しない。

### QEMU 設定

`run-qemu.sh` と `run-selftest.sh` の両方に `-netdev user,id=net1 -device e1000e,netdev=net1` を追加した。最初は `run-qemu.sh` だけ変更してテストが通らず、テスト用の QEMU は `run-selftest.sh` で独自に起動されることに気づいた。

### テスト結果

```
=== SELFTEST END: 59/59 PASSED ===
```

新規追加の `e1000e_detect` を含む全 59 テストが PASS。

---

## 今日のまとめ

Phase 2（ネットワーク実機対応）を 3 つ全て完了した:

| Phase | 内容 | テスト数 |
|-------|------|---------|
| 2-1 | ARP キャッシュ | 57/57 |
| 2-2 | DHCP クライアント | 58/58 |
| 2-3 | e1000e NIC ドライバ | 59/59 |

これで SABOS は実機のネットワーク環境（Intel e1000e NIC + DHCP サーバー）で動作する準備が整った。virtio-net しかない QEMU 環境でも、フォールバック機構のおかげで従来通り動作する。

---

## Phase 3-2: 電源管理（ACPI shutdown / reboot）

### やったこと

これまで SABOS の電源操作は「HLT ループで CPU 停止」か「QEMU 専用 ISA debug exit」しかなかった。実機で使うには ACPI を使って正しくシャットダウン・リブートする必要がある。

#### FADT 解析

ACPI の FADT (Fixed ACPI Description Table) テーブルから電源管理に必要な情報を取得する処理を `acpi.rs` に追加した:

- **PM1a Control Block**: シャットダウン時に SLP_TYP と SLP_EN を書き込む I/O ポート
- **Reset Register**: リブート時に reset_value を書き込むアドレス（I/O ポートまたは MMIO）
- **S5 スリープタイプ**: DSDT の `_S5_` パッケージからバイトスキャンで取得

S5 スリープタイプの取得は面白い実装になった。通常は AML (ACPI Machine Language) インタープリタを使って DSDT を解釈するが、それはかなり大掛かり。代わりに DSDT のバイト列を直接スキャンして `_S5_` という名前のオブジェクトを探し、パッケージの最初の要素（SLP_TYPa）を読み取るという軽量な方法を採用した。

#### shutdown コマンド

PM1a_CNT レジスタに `(SLP_TYPa << 10) | (1 << 13)` を書き込んで S5 ステート（Soft Off）に遷移させる。QEMU ではこの操作で仮想マシンが正常終了する。

#### reboot コマンド

3 段階のフォールバック戦略:
1. **FADT reset register**: ACPI 2.0 標準のリセット方法
2. **8042 キーボードコントローラ**: レガシーなリセット方法（I/O ポート 0x64 に 0xFE を送信）
3. **トリプルフォルト**: IDT を無効化して例外を発生させる最終手段

#### selftest

`acpi_fadt` テストを追加（59 → 60 項目）。FADT から PM1a Control Block と S5 スリープタイプが正しく取得されていることを確認する。

### つまずいたポイント

- **packed struct のアライメント問題**: `acpi` crate の `Fadt` 構造体は `#[repr(C, packed)]` なので、フィールドを直接参照すると Rust のアライメントチェックに引っかかる。`let flags = { fadt.flags };` のようにローカル変数にコピーしてからメソッドを呼ぶ必要があった。

## 気づき・学び

- **BAR は 32-bit と 64-bit がある**。NVMe だけ触っていると 64-bit が当たり前と思い込んでしまうが、e1000e のようなレガシーなデバイスは 32-bit BAR を使う。type bits を見て判定するのが正しいお作法。
- **テストスクリプトが複数箇所に QEMU コマンドを持っている**ことに気づいた。`run-qemu.sh` と `run-selftest.sh` で同じデバイス構成を別々に管理しているのは技術的負債。いずれ共通化したい。
- **NIC 抽象化はフォールバック方式がシンプルで良い**。virtio-net → e1000e の順に試すだけで、設定なしに適切なデバイスが選ばれる。将来 Realtek RTL8168 等を追加しても同じパターンで拡張できる。
- DHCP → ARP → MAC 解決 → IP 通信という一連のフローが、実機と同じ形で動くようになった。QEMU SLIRP の「おまかせ設定」に甘えていた部分を一つずつ自前で実装していく過程は、ネットワークプロトコルの理解が深まって楽しい。
